{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da542328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa97993",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode, step = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f49357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Q-Network for DQN Agent\n",
    "# -----------------------------\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Prioritized Replay Buffer\n",
    "# -----------------------------\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            capacity (int): Maximum number of transitions to store.\n",
    "            alpha (float): How much prioritization is used \n",
    "                           (0 = no prioritization, 1 = full prioritization).\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []             # List to store experiences.\n",
    "        self.priorities = []         # List to store priorities.\n",
    "        self.alpha = alpha\n",
    "        self.pos = 0\n",
    "\n",
    "    def add(self, experience):\n",
    "        \"\"\"Adds an experience to the buffer with maximum priority.\"\"\"\n",
    "        # If the buffer is not full, append the new experience;\n",
    "        # otherwise, replace the oldest one (circular buffer).\n",
    "        max_priority = max(self.priorities) if self.buffer else 1.0\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(experience)\n",
    "            self.priorities.append(max_priority)\n",
    "        else:\n",
    "            self.buffer[self.pos] = experience\n",
    "            self.priorities[self.pos] = max_priority\n",
    "            self.pos = (self.pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        \"\"\"\n",
    "        Samples a batch of experiences with probabilities proportional to their priorities.\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int): Number of samples to draw.\n",
    "            beta (float): Importance-sampling, from initial value increasing to 1.\n",
    "        \n",
    "        Returns:\n",
    "            samples: List of sampled experiences.\n",
    "            indices: The indices of the sampled experiences.\n",
    "            weights: Importance sampling weights for the batch.\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        prios = np.array(self.priorities, dtype=np.float32)\n",
    "        probs = prios ** self.alpha\n",
    "        probs_sum = probs.sum()\n",
    "        if probs_sum == 0 or np.isnan(probs_sum):\n",
    "            probs = np.ones_like(probs) / len(probs)\n",
    "        else:\n",
    "            probs /= probs_sum\n",
    "\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[i] for i in indices]\n",
    "\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()  # Normalize\n",
    "\n",
    "        return samples, indices, weights\n",
    "    \n",
    "\n",
    "    def update_priorities(self, indices, new_priorities):\n",
    "        \"\"\"\n",
    "        Updates the priorities of sampled experiences.\n",
    "        \n",
    "        Args:\n",
    "            indices (list of int): The indices of the experiences to update.\n",
    "            new_priorities (list of float): The new priority for each corresponding experience.\n",
    "        \"\"\"\n",
    "        for idx, priority in zip(indices, new_priorities):\n",
    "            self.priorities[idx] = priority\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump((self.buffer, self.priorities, self.pos), f)\n",
    "        print(f\"Replay buffer saved to {filepath}\")\n",
    "\n",
    "    def load(self, filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            self.buffer, self.priorities, self.pos = pickle.load(f)\n",
    "        print(f\"Replay buffer loaded from {filepath}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DQN Agent\n",
    "# -----------------------------\n",
    "class DQNAgent:\n",
    "    def __init__(self, action_space, state_space, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_min=0.1, \n",
    "                 epsilon_decay=0.995, batch_size=64, buffer_size=10000):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.step = 0  # <--- Track steps here\n",
    "\n",
    "        self.q_network = QNetwork(state_space, action_space).to(self.device)\n",
    "        self.target_network = QNetwork(state_space, action_space).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)\n",
    "        self.buffer = PrioritizedReplayBuffer(buffer_size)\n",
    "\n",
    "        self.update_target_network()\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_space)\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        q_values = self.q_network(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "    def train(self, beta=0.4):\n",
    "        if self.buffer.size() < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch, indices, weights = self.buffer.sample(self.batch_size, beta)\n",
    "        if not batch:\n",
    "            return  # Safety check\n",
    "\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = torch.FloatTensor(np.array(states)).to(self.device)\n",
    "        actions = torch.LongTensor(actions).unsqueeze(1).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(1).to(self.device)\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(1).to(self.device)\n",
    "        weights = torch.FloatTensor(weights).unsqueeze(1).to(self.device)\n",
    "\n",
    "        q_values = self.q_network(states).gather(1, actions)\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_network(next_states).max(1, keepdim=True)[0]\n",
    "            target_q_values = rewards + self.gamma * next_q_values * (1 - dones)\n",
    "\n",
    "        td_errors = q_values - target_q_values\n",
    "        loss = (weights * td_errors.pow(2)).mean()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update priorities, ensure they are not zero to avoid sampling issues\n",
    "        new_priorities = td_errors.abs().detach().cpu().numpy().flatten() + 1e-6\n",
    "        self.buffer.update_priorities(indices, new_priorities)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "    def save(self, filepath, episode, step):\n",
    "        torch.save({\n",
    "            'policy_net_state_dict': self.q_network.state_dict(),\n",
    "            'target_net_state_dict': self.target_network.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'episode': episode,\n",
    "            'step': step,\n",
    "            'epsilon': self.epsilon\n",
    "        }, filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=self.device)\n",
    "        self.q_network.load_state_dict(checkpoint['policy_net_state_dict'])\n",
    "        self.target_network.load_state_dict(checkpoint['target_net_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        episode = checkpoint.get('episode', 0)\n",
    "        step = checkpoint.get('step', 0)\n",
    "        self.epsilon = checkpoint.get('epsilon', 1.0)\n",
    "        print(f\"Loaded model from {filepath} | episode: {episode} | step: {step} | epsilon: {self.epsilon:.4f}\")\n",
    "        return episode, step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0069e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Collect & Avoid Environment (gym.Env subclass)\n",
    "# -------------------------------------------\n",
    "\n",
    "class CollectAvoidEnv(gym.Env):\n",
    "    def __init__(self, grid_size=15, num_rewards=5, num_enemies=3, enemy_random_move_ratio=0.5):\n",
    "        super(CollectAvoidEnv, self).__init__()\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "        self.num_rewards = num_rewards\n",
    "        self.num_enemies = num_enemies\n",
    "        self.enemy_random_move_ratio = enemy_random_move_ratio\n",
    "        self.reward_positions = []\n",
    "        self.enemy_positions = []\n",
    "        self.agent_pos = None\n",
    "\n",
    "        # Action space: 5 discrete actions\n",
    "        self.action_space = spaces.Discrete(5)  # 5 actions: stay, up, down, left, right\n",
    "\n",
    "        # Observation space: grid_size x grid_size grid\n",
    "        self.observation_space = spaces.Box(low=0, high=3, shape=(grid_size, grid_size), dtype=int)\n",
    "\n",
    "        # Initialize the plot and axis only once\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 6))\n",
    "        self.ax.set_xlim(0, self.grid_size - 1)\n",
    "        self.ax.set_ylim(0, self.grid_size - 1)\n",
    "        self.ax.set_xticks(range(self.grid_size))\n",
    "        self.ax.set_yticks(range(self.grid_size))\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.reset()  # Initialize the environment state\n",
    "\n",
    "    def reset(self):\n",
    "        # Initialize positions of rewards, enemies, and agent\n",
    "        self.reward_positions = [self._random_empty_cell([]) for _ in range(self.num_rewards)]\n",
    "        self.enemy_positions = [self._random_empty_cell(self.reward_positions) for _ in range(self.num_enemies)]\n",
    "        self.agent_pos = self._random_empty_cell(self.reward_positions + self.enemy_positions)\n",
    "\n",
    "        return self._get_state()\n",
    "\n",
    "    def render(self, episode, step, reward=None):\n",
    "        # Clear the previous points from the figure, but don't recreate the entire plot\n",
    "        self.ax.clear()\n",
    "        self.ax.set_xlim(0, self.grid_size - 1)\n",
    "        self.ax.set_ylim(0, self.grid_size - 1)\n",
    "        self.ax.set_xticks(range(self.grid_size))\n",
    "        self.ax.set_yticks(range(self.grid_size))\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        # Plot agent, rewards, and enemies\n",
    "        self.ax.plot(self.agent_pos[0], self.agent_pos[1], 'bo', markersize=10)  # Agent as blue circle\n",
    "        for r_pos in self.reward_positions:\n",
    "            self.ax.plot(r_pos[0], r_pos[1], 'go', markersize=10)  # Reward as green circle\n",
    "        for e_pos in self.enemy_positions:\n",
    "            self.ax.plot(e_pos[0], e_pos[1], 'ro', markersize=10)  # Enemy as red circle\n",
    "\n",
    "        # Display the episode, step, and reward on the plot\n",
    "        self.ax.text(0.5, self.grid_size - 1, f'Episode: {episode}, Step: {step}', \n",
    "                    horizontalalignment='center', verticalalignment='top', fontsize=12, color='black', weight='bold')\n",
    "\n",
    "        if reward is not None:\n",
    "            reward_color = 'green' if reward > 0 else 'red' if reward < 0 else 'black'\n",
    "            self.ax.text(0.5, self.grid_size - 2, f'Reward: {reward:.2f}', \n",
    "                        horizontalalignment='center', verticalalignment='top', fontsize=12, color=reward_color, weight='bold')\n",
    "\n",
    "        # Display the updated plot\n",
    "        clear_output(wait=True)\n",
    "        display(self.fig)\n",
    "        \n",
    "\n",
    "    def step(self, action, episode, step):\n",
    "        prev_agent_pos = self.agent_pos\n",
    "\n",
    "        # Move agent\n",
    "        if action == 0:  # stay\n",
    "            new_pos = self.agent_pos\n",
    "        elif action == 1:  # up\n",
    "            new_pos = (max(self.agent_pos[0] - 1, 0), self.agent_pos[1])\n",
    "        elif action == 2:  # down\n",
    "            new_pos = (min(self.agent_pos[0] + 1, self.grid_size - 1), self.agent_pos[1])\n",
    "        elif action == 3:  # left\n",
    "            new_pos = (self.agent_pos[0], max(self.agent_pos[1] - 1, 0))\n",
    "        elif action == 4:  # right\n",
    "            new_pos = (self.agent_pos[0], min(self.agent_pos[1] + 1, self.grid_size - 1))\n",
    "\n",
    "        self.agent_pos = new_pos\n",
    "\n",
    "        # Move enemies\n",
    "        self._move_enemies()\n",
    "\n",
    "        # Compute reward\n",
    "        reward = self._compute_reward(prev_agent_pos)\n",
    "\n",
    "        # Check terminal state\n",
    "        done = self.agent_pos in self.enemy_positions\n",
    "\n",
    "        self.render(episode, step, reward)\n",
    "        return self._get_state(), reward, done, {}\n",
    "    \n",
    "    def _compute_reward(self, prev_agent_pos):\n",
    "        reward = 0.0\n",
    "\n",
    "        if self.agent_pos in self.reward_positions:\n",
    "            self.reward_positions.remove(self.agent_pos)\n",
    "            reward += 3.0\n",
    "\n",
    "        for rx, ry in self.reward_positions:\n",
    "            dist = abs(self.agent_pos[0] - rx) + abs(self.agent_pos[1] - ry)\n",
    "            if dist == 1: reward += 0.2\n",
    "            elif dist == 2: reward += 0.15\n",
    "            elif dist == 3: reward += 0.1\n",
    "\n",
    "        for ex, ey in self.enemy_positions:\n",
    "            edist = abs(self.agent_pos[0] - ex) + abs(self.agent_pos[1] - ey)\n",
    "            if edist == 1: reward -= 1\n",
    "            elif edist == 2: reward -= 0.5\n",
    "            elif edist == 3: reward -= 0.3\n",
    "            elif edist == 4: reward -= 0.2\n",
    "\n",
    "        if self.enemy_positions:\n",
    "            prev_avg = np.mean([abs(prev_agent_pos[0] - ex) + abs(prev_agent_pos[1] - ey) for ex, ey in self.enemy_positions])\n",
    "            curr_avg = np.mean([abs(self.agent_pos[0] - ex) + abs(self.agent_pos[1] - ey) for ex, ey in self.enemy_positions])\n",
    "            if curr_avg > prev_avg: reward += 0.3\n",
    "            elif curr_avg < prev_avg: reward -= 0.3\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def _move_enemies(self):\n",
    "        \"\"\"Move enemies (either move towards agent or randomly).\"\"\"\n",
    "        for i in range(len(self.enemy_positions)):\n",
    "            x, y = self.enemy_positions[i]\n",
    "\n",
    "            # Calculate Euclidean distance to the agent\n",
    "            ax, ay = self.agent_pos\n",
    "            distance = math.sqrt((ax - x) ** 2 + (ay - y) ** 2)\n",
    "\n",
    "            if random.random() < (1 -self.enemy_random_move_ratio):  # 50% chance to move towards agent\n",
    "                # Move towards agent to reduce distance by 50%\n",
    "                if ax > x:\n",
    "                    x += 1\n",
    "                elif ax < x:\n",
    "                    x -= 1\n",
    "                if ay > y:\n",
    "                    y += 1\n",
    "                elif ay < y:\n",
    "                    y -= 1\n",
    "            else:\n",
    "                # Move randomly in one of the four directions\n",
    "                direction = random.choice([(0, 1), (1, 0), (0, -1), (-1, 0)])\n",
    "                x = max(0, min(self.grid_size - 1, x + direction[0]))\n",
    "                y = max(0, min(self.grid_size - 1, y + direction[1]))\n",
    "\n",
    "            self.enemy_positions[i] = (x, y)\n",
    "\n",
    "    def _get_state(self):\n",
    "        state = np.zeros((self.grid_size, self.grid_size))\n",
    "        state[self.agent_pos] = 1  # Mark the agent's position\n",
    "        for r_pos in self.reward_positions:\n",
    "            state[r_pos] = 2  # Mark rewards\n",
    "        for e_pos in self.enemy_positions:\n",
    "            state[e_pos] = 3  # Mark enemies\n",
    "        return state.flatten()\n",
    "\n",
    "    def _random_empty_cell(self, excluded_cells):\n",
    "        \"\"\"Generate a random empty cell, excluding positions in `excluded_cells`.\"\"\"\n",
    "        while True:\n",
    "            cell = (random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1))\n",
    "            if cell not in excluded_cells:\n",
    "                return cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e20c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1104 S4 | reward: -0.600 | epsilon: 0.200 | beta: 0.930\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Train the Agent\n",
    "# -------------------------------------------\n",
    "\n",
    "\"\"\" Input Variables \"\"\"\n",
    "GRID_SIZE = 15\n",
    "NUM_REWARDS = 8\n",
    "NUM_ENEMIES = 1\n",
    "ENEMY_RANDOM_MOVE_RATIO = 0.6\n",
    "NUMBER_OF_EPISODES = 10000\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.95  # 0: only immediate reward matters ; 1.0: future rewards are just as important as immediate ones.\n",
    "EPSILON = 1.0   # initial value for weighting random over policy in taking actions\n",
    "EPSILON_MIN = 0.2\n",
    "EPSILON_DECAY = 0.9999  # multiplies random action chance with this factor after every training\n",
    "BATCH_SIZE = 8  # number of samples to take from the replay buffer for training\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# Define the annealing parameters for beta (Priotrized Replay Buffer)\n",
    "BETA_START = 0.4  # Starting value for beta (usually smaller)\n",
    "BEAT_FRAMES = 10  # Number of frames after which beta will reach 1.0\n",
    "TOTAL_FRAMES = NUMBER_OF_EPISODES * 100  # Total frames in the training\n",
    "\n",
    "RESUME_TRAINING = True\n",
    "MODEL_PATH = r\"E:\\Git_repos\\RL_playground\\CollectAndAvoid\\trained_models\\dqn_model_4.pth\"\n",
    "BUFFER_PATH = r\"E:\\Git_repos\\RL_playground\\CollectAndAvoid\\trained_models\\buffer_4.pth\"\n",
    "\"\"\" END of Input Variables \"\"\"\n",
    "\n",
    "env = CollectAvoidEnv(grid_size=GRID_SIZE, num_rewards=NUM_REWARDS, num_enemies=NUM_ENEMIES, enemy_random_move_ratio=ENEMY_RANDOM_MOVE_RATIO)\n",
    "agent = DQNAgent(env.action_space.n, np.prod(env.observation_space.shape), lr=LEARNING_RATE, gamma=GAMMA, epsilon=EPSILON,\n",
    "                 epsilon_min=EPSILON_MIN, epsilon_decay=EPSILON_DECAY, batch_size=BATCH_SIZE, buffer_size=BUFFER_SIZE)\n",
    "\n",
    "start_episode = 0\n",
    "start_step = 0\n",
    "\n",
    "# Try loading an existing model\n",
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "         start_episode, start_step = agent.load(MODEL_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved model found, starting from scratch.\")\n",
    "\n",
    "# Try loading an existing buffer\n",
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "        agent.buffer.load(BUFFER_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved buffer found, starting with empty buffer.\")\n",
    "\n",
    "\n",
    "for episode in range(start_episode, NUMBER_OF_EPISODES):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "\n",
    "    # Calculate beta for the current training step (frame_idx)\n",
    "    frame_idx = episode * 50 + step  # Adjust this according to your setup\n",
    "    beta = min(1.0, BETA_START + (BEAT_FRAMES - BETA_START) * frame_idx / TOTAL_FRAMES)\n",
    "    while not done:\n",
    "        action = agent.act(state)  # Get action from your agent\n",
    "        next_state, reward, done, _ = env.step(action, episode, step)\n",
    "        step += 1\n",
    "        agent.buffer.add((state.flatten(), action, reward, next_state.flatten(), float(done)))\n",
    "\n",
    "        print(f\"E{episode} S{step} | reward: {reward:.3f} | epsilon: {agent.epsilon:.3f} | beta: {beta:.3f}\")\n",
    "\n",
    "        agent.train(beta=beta)\n",
    "        # if episode > 2000:\n",
    "        #     time.sleep(0.1)\n",
    "    if episode % 10 == 0:\n",
    "        agent.update_target_network()\n",
    "        agent.save(MODEL_PATH, episode, step)\n",
    "        agent.buffer.save(BUFFER_PATH)\n",
    "        print(\"Model and Buffer saved.\")\n",
    "    print(f\"Episode {episode + 1} finished\")\n",
    "\n",
    "agent.save(MODEL_PATH, episode, step)\n",
    "agent.buffer.save(BUFFER_PATH)\n",
    "print(\"Training complete, model and buffer saved.\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b0d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
