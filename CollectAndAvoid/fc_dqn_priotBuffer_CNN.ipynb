{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da542328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fa97993",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode, step = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f49357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Q-Network for DQN Agent\n",
    "# -----------------------------\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_channels, num_actions):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),  # [B, 32, H, W]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),              # [B, 64, H, W]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),              # [B, 64, H, W]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Flatten after conv layers\n",
    "        self.fc_input_size = None  # Placeholder, will be set dynamically\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 15 * 15, 512),  # Update based on actual grid size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Prioritized Replay Buffer\n",
    "# -----------------------------\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            capacity (int): Maximum number of transitions to store.\n",
    "            alpha (float): How much prioritization is used \n",
    "                           (0 = no prioritization, 1 = full prioritization).\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []             # List to store experiences.\n",
    "        self.priorities = []         # List to store priorities.\n",
    "        self.alpha = alpha\n",
    "        self.pos = 0\n",
    "\n",
    "    def add(self, experience):\n",
    "        \"\"\"Adds an experience to the buffer with maximum priority.\"\"\"\n",
    "        # If the buffer is not full, append the new experience;\n",
    "        # otherwise, replace the oldest one (circular buffer).\n",
    "        max_priority = max(self.priorities) if self.buffer else 1.0\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(experience)\n",
    "            self.priorities.append(max_priority)\n",
    "        else:\n",
    "            self.buffer[self.pos] = experience\n",
    "            self.priorities[self.pos] = max_priority\n",
    "            self.pos = (self.pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        \"\"\"\n",
    "        Samples a batch of experiences with probabilities proportional to their priorities.\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int): Number of samples to draw.\n",
    "            beta (float): Importance-sampling, from initial value increasing to 1.\n",
    "        \n",
    "        Returns:\n",
    "            samples: List of sampled experiences.\n",
    "            indices: The indices of the sampled experiences.\n",
    "            weights: Importance sampling weights for the batch.\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        prios = np.array(self.priorities, dtype=np.float32)\n",
    "        probs = prios ** self.alpha\n",
    "        probs_sum = probs.sum()\n",
    "        if probs_sum == 0 or np.isnan(probs_sum):\n",
    "            probs = np.ones_like(probs) / len(probs)\n",
    "        else:\n",
    "            probs /= probs_sum\n",
    "\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[i] for i in indices]\n",
    "\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()  # Normalize\n",
    "\n",
    "        return samples, indices, weights\n",
    "    \n",
    "\n",
    "    def update_priorities(self, indices, new_priorities):\n",
    "        \"\"\"\n",
    "        Updates the priorities of sampled experiences.\n",
    "        \n",
    "        Args:\n",
    "            indices (list of int): The indices of the experiences to update.\n",
    "            new_priorities (list of float): The new priority for each corresponding experience.\n",
    "        \"\"\"\n",
    "        for idx, priority in zip(indices, new_priorities):\n",
    "            self.priorities[idx] = priority\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump((self.buffer, self.priorities, self.pos), f)\n",
    "        print(f\"Replay buffer saved to {filepath}\")\n",
    "\n",
    "    def load(self, filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            self.buffer, self.priorities, self.pos = pickle.load(f)\n",
    "        print(f\"Replay buffer loaded from {filepath}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DQN Agent\n",
    "# -----------------------------\n",
    "class DQNAgent:\n",
    "    def __init__(self, action_space, state_space, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_min=0.1, \n",
    "                 epsilon_decay=0.995, batch_size=64, buffer_size=10000):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.step = 0  # <--- Track steps here\n",
    "\n",
    "        input_channels = 3  # Agent, rewards, enemies\n",
    "\n",
    "        self.q_network = QNetwork(input_channels, action_space).to(self.device)\n",
    "        self.target_network = QNetwork(input_channels, action_space).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)\n",
    "        self.buffer = PrioritizedReplayBuffer(buffer_size)\n",
    "\n",
    "        self.update_target_network()\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_space)\n",
    "        \n",
    "        # Convert to shape [1, C, H, W] assuming 3-channel input (C=3)\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)  # [1, 3, H, W]\n",
    "        q_values = self.q_network(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, beta=0.4):\n",
    "        if self.buffer.size() < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch, indices, weights = self.buffer.sample(self.batch_size, beta)\n",
    "        if not batch:\n",
    "            return  # Safety check\n",
    "\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        # Convert batch to tensors\n",
    "        # Shape: [B, 3, H, W] assuming 3-channel grid input\n",
    "        states = torch.FloatTensor(np.array(states)).to(self.device)  # [B, 3, H, W]\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(self.device)  # [B, 3, H, W]\n",
    "        actions = torch.LongTensor(actions).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        weights = torch.FloatTensor(weights).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "\n",
    "        # Forward pass\n",
    "        q_values = self.q_network(states).gather(1, actions)  # [B, 1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_network(next_states).max(1, keepdim=True)[0]  # [B, 1]\n",
    "            target_q_values = rewards + self.gamma * next_q_values * (1 - dones)\n",
    "\n",
    "        td_errors = q_values - target_q_values\n",
    "        loss = (weights * td_errors.pow(2)).mean()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update priorities\n",
    "        new_priorities = td_errors.abs().detach().cpu().numpy().flatten() + 1e-6\n",
    "        self.buffer.update_priorities(indices, new_priorities)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save(self, filepath, episode, step):\n",
    "        torch.save({\n",
    "            'policy_net_state_dict': self.q_network.state_dict(),\n",
    "            'target_net_state_dict': self.target_network.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'episode': episode,\n",
    "            'step': step,\n",
    "            'epsilon': self.epsilon\n",
    "        }, filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=self.device)\n",
    "        self.q_network.load_state_dict(checkpoint['policy_net_state_dict'])\n",
    "        self.target_network.load_state_dict(checkpoint['target_net_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        episode = checkpoint.get('episode', 0)\n",
    "        step = checkpoint.get('step', 0)\n",
    "        self.epsilon = checkpoint.get('epsilon', 1.0)\n",
    "        print(f\"Loaded model from {filepath} | episode: {episode} | step: {step} | epsilon: {self.epsilon:.4f}\")\n",
    "        return episode, step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0069e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Collect & Avoid Environment (gym.Env subclass)\n",
    "# -------------------------------------------\n",
    "\n",
    "class CollectAvoidEnv(gym.Env):\n",
    "    def __init__(self, grid_size=15, num_rewards=5, num_enemies=3, enemy_random_move_ratio=0.5, max_steps=1000):\n",
    "        super(CollectAvoidEnv, self).__init__()\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "        self.num_rewards = num_rewards\n",
    "        self.num_enemies = num_enemies\n",
    "        self.enemy_random_move_ratio = enemy_random_move_ratio\n",
    "        self.reward_positions = []\n",
    "        self.enemy_positions = []\n",
    "        self.agent_pos = None\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Action space: 5 discrete actions\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "\n",
    "        # Observation space: 3-channel grid (agent, rewards, enemies)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0.0, high=1.0,\n",
    "            shape=(3, self.grid_size, self.grid_size),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Plotting setup\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 6))\n",
    "        self.ax.set_xlim(0, self.grid_size - 1)\n",
    "        self.ax.set_ylim(0, self.grid_size - 1)\n",
    "        self.ax.set_xticks(range(self.grid_size))\n",
    "        self.ax.set_yticks(range(self.grid_size))\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.reward_positions = [self._random_empty_cell([]) for _ in range(self.num_rewards)]\n",
    "        self.enemy_positions = [self._random_empty_cell(self.reward_positions) for _ in range(self.num_enemies)]\n",
    "        self.agent_pos = self._random_empty_cell(self.reward_positions + self.enemy_positions)\n",
    "        self.current_step = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def step(self, action, episode, step):\n",
    "        self.current_step += 1\n",
    "        prev_agent_pos = self.agent_pos\n",
    "\n",
    "        # Move agent\n",
    "        if action == 0:  # stay\n",
    "            new_pos = self.agent_pos\n",
    "        elif action == 1:  # up\n",
    "            new_pos = (max(self.agent_pos[0] - 1, 0), self.agent_pos[1])\n",
    "        elif action == 2:  # down\n",
    "            new_pos = (min(self.agent_pos[0] + 1, self.grid_size - 1), self.agent_pos[1])\n",
    "        elif action == 3:  # left\n",
    "            new_pos = (self.agent_pos[0], max(self.agent_pos[1] - 1, 0))\n",
    "        elif action == 4:  # right\n",
    "            new_pos = (self.agent_pos[0], min(self.agent_pos[1] + 1, self.grid_size - 1))\n",
    "\n",
    "        self.agent_pos = new_pos\n",
    "\n",
    "        # Move enemies\n",
    "        self._move_enemies()\n",
    "\n",
    "        # Compute reward and check if agent is caught by an enemy or has collected all rewards\n",
    "        reward = self._compute_reward(prev_agent_pos)\n",
    "        done = self.agent_pos in self.enemy_positions or len(self.reward_positions) == 0 or self.current_step >= self.max_steps # Terminate if caught by enemy or all rewards are collected\n",
    "\n",
    "        # Render environment\n",
    "        self.render(episode, step, reward)\n",
    "        return self._get_state(), reward, done, {}\n",
    "\n",
    "    def _get_state(self):\n",
    "        state = np.zeros((3, self.grid_size, self.grid_size), dtype=np.float32)\n",
    "\n",
    "        # Agent in channel 0\n",
    "        state[0, self.agent_pos[0], self.agent_pos[1]] = 1.0\n",
    "\n",
    "        # Rewards in channel 1\n",
    "        for r in self.reward_positions:\n",
    "            state[1, r[0], r[1]] = 1.0\n",
    "\n",
    "        # Enemies in channel 2\n",
    "        for e in self.enemy_positions:\n",
    "            state[2, e[0], e[1]] = 1.0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _compute_reward(self, prev_agent_pos):\n",
    "        reward = 0.0\n",
    "\n",
    "        if self.agent_pos in self.reward_positions:\n",
    "            self.reward_positions.remove(self.agent_pos)\n",
    "            reward += 3.0\n",
    "\n",
    "        # Reward for being near remaining rewards\n",
    "        for rx, ry in self.reward_positions:\n",
    "            dist = abs(self.agent_pos[0] - rx) + abs(self.agent_pos[1] - ry)\n",
    "            if dist == 1: reward += 0.2\n",
    "            elif dist == 2: reward += 0.15\n",
    "            elif dist == 3: reward += 0.1\n",
    "\n",
    "        # Penalty for being near enemies\n",
    "        for ex, ey in self.enemy_positions:\n",
    "            edist = abs(self.agent_pos[0] - ex) + abs(self.agent_pos[1] - ey)\n",
    "            if edist == 1: reward -= 1\n",
    "            elif edist == 2: reward -= 0.5\n",
    "            elif edist == 3: reward -= 0.3\n",
    "            elif edist == 4: reward -= 0.2\n",
    "\n",
    "        # Reward for increasing distance from enemies\n",
    "        if self.enemy_positions:\n",
    "            prev_avg = np.mean([abs(prev_agent_pos[0] - ex) + abs(prev_agent_pos[1] - ey) for ex, ey in self.enemy_positions])\n",
    "            curr_avg = np.mean([abs(self.agent_pos[0] - ex) + abs(self.agent_pos[1] - ey) for ex, ey in self.enemy_positions])\n",
    "            if curr_avg > prev_avg: reward += 0.3\n",
    "            elif curr_avg < prev_avg: reward -= 0.3\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def _move_enemies(self):\n",
    "        for i in range(len(self.enemy_positions)):\n",
    "            x, y = self.enemy_positions[i]\n",
    "            ax, ay = self.agent_pos\n",
    "\n",
    "            if random.random() < (1 - self.enemy_random_move_ratio):\n",
    "                if ax > x: x += 1\n",
    "                elif ax < x: x -= 1\n",
    "                if ay > y: y += 1\n",
    "                elif ay < y: y -= 1\n",
    "            else:\n",
    "                dx, dy = random.choice([(0, 1), (1, 0), (0, -1), (-1, 0)])\n",
    "                x = max(0, min(self.grid_size - 1, x + dx))\n",
    "                y = max(0, min(self.grid_size - 1, y + dy))\n",
    "\n",
    "            self.enemy_positions[i] = (x, y)\n",
    "\n",
    "    def _random_empty_cell(self, excluded_cells):\n",
    "        while True:\n",
    "            cell = (random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1))\n",
    "            if cell not in excluded_cells:\n",
    "                return cell\n",
    "\n",
    "    def render(self, episode, step, reward=None):\n",
    "        self.ax.clear()\n",
    "        self.ax.set_xlim(0, self.grid_size - 1)\n",
    "        self.ax.set_ylim(0, self.grid_size - 1)\n",
    "        self.ax.set_xticks(range(self.grid_size))\n",
    "        self.ax.set_yticks(range(self.grid_size))\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.ax.plot(self.agent_pos[0], self.agent_pos[1], 'bo', markersize=10)\n",
    "        for r_pos in self.reward_positions:\n",
    "            self.ax.plot(r_pos[0], r_pos[1], 'go', markersize=10)\n",
    "        for e_pos in self.enemy_positions:\n",
    "            self.ax.plot(e_pos[0], e_pos[1], 'ro', markersize=10)\n",
    "\n",
    "        self.ax.text(0.5, self.grid_size - 1, f'Episode: {episode}, Step: {step}',\n",
    "                     horizontalalignment='center', verticalalignment='top', fontsize=12, color='black', weight='bold')\n",
    "\n",
    "        if reward is not None:\n",
    "            reward_color = 'green' if reward > 0 else 'red' if reward < 0 else 'black'\n",
    "            self.ax.text(0.5, self.grid_size - 2, f'Reward: {reward:.2f}',\n",
    "                         horizontalalignment='center', verticalalignment='top', fontsize=12, color=reward_color, weight='bold')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(self.fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e20c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2 S42 | reward: 0.150 | epsilon: 0.987 | beta: 0.401\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m     63\u001b[39m     action = agent.act(state)  \u001b[38;5;66;03m# Get action from your agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     next_state, reward, done, _ = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     step += \u001b[32m1\u001b[39m\n\u001b[32m     66\u001b[39m     agent.buffer.add((state, action, reward, next_state, \u001b[38;5;28mfloat\u001b[39m(done)))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mCollectAvoidEnv.step\u001b[39m\u001b[34m(self, action, episode, step)\u001b[39m\n\u001b[32m     69\u001b[39m done = \u001b[38;5;28mself\u001b[39m.agent_pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enemy_positions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.reward_positions) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_step >= \u001b[38;5;28mself\u001b[39m.max_steps \u001b[38;5;66;03m# Terminate if caught by enemy or all rewards are collected\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Render environment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_state(), reward, done, {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 150\u001b[39m, in \u001b[36mCollectAvoidEnv.render\u001b[39m\u001b[34m(self, episode, step, reward)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28mself\u001b[39m.ax.set_ylim(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m.grid_size - \u001b[32m1\u001b[39m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.ax.set_xticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.grid_size))\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_yticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m.ax.grid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28mself\u001b[39m.ax.plot(\u001b[38;5;28mself\u001b[39m.agent_pos[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.agent_pos[\u001b[32m1\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mbo\u001b[39m\u001b[33m'\u001b[39m, markersize=\u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axes\\_base.py:74\u001b[39m, in \u001b[36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:2218\u001b[39m, in \u001b[36mAxis.set_ticks\u001b[39m\u001b[34m(self, ticks, labels, minor, **kwargs)\u001b[39m\n\u001b[32m   2213\u001b[39m     first_key = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\n\u001b[32m   2214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2215\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncorrect use of keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_key\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m. Keyword arguments \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mother than \u001b[39m\u001b[33m'\u001b[39m\u001b[33mminor\u001b[39m\u001b[33m'\u001b[39m\u001b[33m modify the text labels and can only be used if \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m\u001b[33m are passed as well.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2218\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_tick_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2220\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_ticklabels(labels, minor=minor, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:2170\u001b[39m, in \u001b[36mAxis._set_tick_locations\u001b[39m\u001b[34m(self, ticks, minor)\u001b[39m\n\u001b[32m   2168\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2169\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_major_locator(locator)\n\u001b[32m-> \u001b[39m\u001b[32m2170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_major_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mticks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:1664\u001b[39m, in \u001b[36mAxis.get_major_ticks\u001b[39m\u001b[34m(self, numticks)\u001b[39m\n\u001b[32m   1660\u001b[39m     numticks = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.get_majorticklocs())\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.majorTicks) < numticks:\n\u001b[32m   1663\u001b[39m     \u001b[38;5;66;03m# Update the new tick label properties from the old.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1664\u001b[39m     tick = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1665\u001b[39m     \u001b[38;5;28mself\u001b[39m.majorTicks.append(tick)\n\u001b[32m   1666\u001b[39m     \u001b[38;5;28mself\u001b[39m._copy_tick_props(\u001b[38;5;28mself\u001b[39m.majorTicks[\u001b[32m0\u001b[39m], tick)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:1592\u001b[39m, in \u001b[36mAxis._get_tick\u001b[39m\u001b[34m(self, major)\u001b[39m\n\u001b[32m   1588\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1589\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe Axis subclass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must define \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1590\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_tick_class or reimplement _get_tick()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1591\u001b[39m tick_kw = \u001b[38;5;28mself\u001b[39m._major_tick_kw \u001b[38;5;28;01mif\u001b[39;00m major \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._minor_tick_kw\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tick_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtick_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:429\u001b[39m, in \u001b[36mYTick.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     \u001b[38;5;66;03m# x in axes coords, y in data coords\u001b[39;00m\n\u001b[32m    431\u001b[39m     ax = \u001b[38;5;28mself\u001b[39m.axes\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:159\u001b[39m, in \u001b[36mTick.__init__\u001b[39m\u001b[34m(self, axes, loc, size, width, color, tickdir, pad, labelsize, labelcolor, labelfontfamily, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m grid_kw = {k[\u001b[32m5\u001b[39m:]: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items()}\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.tick1line = mlines.Line2D(\n\u001b[32m    155\u001b[39m     [], [],\n\u001b[32m    156\u001b[39m     color=color, linestyle=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m, zorder=zorder, visible=tick1On,\n\u001b[32m    157\u001b[39m     markeredgecolor=color, markersize=size, markeredgewidth=width,\n\u001b[32m    158\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28mself\u001b[39m.tick2line = \u001b[43mmlines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLine2D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinestyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzorder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzorder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisible\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtick2On\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmarkeredgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkersize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkeredgewidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28mself\u001b[39m.gridline = mlines.Line2D(\n\u001b[32m    165\u001b[39m     [], [],\n\u001b[32m    166\u001b[39m     color=grid_color, alpha=grid_alpha, visible=gridOn,\n\u001b[32m    167\u001b[39m     linestyle=grid_linestyle, linewidth=grid_linewidth, marker=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    168\u001b[39m     **grid_kw,\n\u001b[32m    169\u001b[39m )\n\u001b[32m    170\u001b[39m \u001b[38;5;28mself\u001b[39m.gridline.get_path()._interpolation_steps = \\\n\u001b[32m    171\u001b[39m     GRIDLINE_INTERPOLATION_STEPS\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\lines.py:331\u001b[39m, in \u001b[36mLine2D.__init__\u001b[39m\u001b[34m(self, xdata, ydata, linewidth, linestyle, color, gapcolor, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[39m\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mydata must be a sequence\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m linewidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     linewidth = \u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlines.linewidth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m linestyle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    334\u001b[39m     linestyle = mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mlines.linestyle\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\__init__.py:799\u001b[39m, in \u001b[36mRcParams.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m    797\u001b[39m         plt.switch_backend(rcsetup._auto_backend_sentinel)\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\__init__.py:698\u001b[39m, in \u001b[36mRcParams._get\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    679\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    680\u001b[39m \u001b[33;03m    Directly write data bypassing deprecation and validation logic.\u001b[39;00m\n\u001b[32m    681\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    694\u001b[39m \u001b[33;03m    :meta public:\u001b[39;00m\n\u001b[32m    695\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    696\u001b[39m     \u001b[38;5;28mdict\u001b[39m.\u001b[34m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, val)\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m    699\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    700\u001b[39m \u001b[33;03m    Directly read data bypassing deprecation, backend and validation\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[33;03m    logic.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    715\u001b[39m \u001b[33;03m    :meta public:\u001b[39;00m\n\u001b[32m    716\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m.\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Train the Agent\n",
    "# -------------------------------------------\n",
    "\n",
    "\"\"\" Input Variables \"\"\"\n",
    "GRID_SIZE = 15\n",
    "NUM_REWARDS = 8\n",
    "NUM_ENEMIES = 0\n",
    "ENEMY_RANDOM_MOVE_RATIO = 0.6\n",
    "NUMBER_OF_EPISODES = 10000\n",
    "MAX_STEPS_PER_EPISODE= 700\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.95  # 0: only immediate reward matters ; 1.0: future rewards are just as important as immediate ones.\n",
    "EPSILON = 1.0   # initial value for weighting random over policy in taking actions\n",
    "EPSILON_MIN = 0.2\n",
    "EPSILON_DECAY = 0.9999  # multiplies random action chance with this factor after every training\n",
    "BATCH_SIZE = 8  # number of samples to take from the replay buffer for training\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# Define the annealing parameters for beta (Prioritized Replay Buffer)\n",
    "BETA_START = 0.4  # Starting value for beta (usually smaller)\n",
    "BEAT_FRAMES = 10  # Number of frames after which beta will reach 1.0\n",
    "TOTAL_FRAMES = NUMBER_OF_EPISODES * 100  # Total frames in the training\n",
    "\n",
    "RESUME_TRAINING = False\n",
    "MODEL_PATH = r\"E:\\Git_repos\\RL_playground\\CollectAndAvoid\\trained_models\\cnn_models\\dqn_cnn_model_1.pth\"\n",
    "BUFFER_PATH = r\"E:\\Git_repos\\RL_playground\\CollectAndAvoid\\trained_models\\cnn_models\\buffer_CNN_1.pth\"\n",
    "\"\"\" END of Input Variables \"\"\"\n",
    "\n",
    "env = CollectAvoidEnv(grid_size=GRID_SIZE, num_rewards=NUM_REWARDS, num_enemies=NUM_ENEMIES, enemy_random_move_ratio=ENEMY_RANDOM_MOVE_RATIO, max_steps=MAX_STEPS_PER_EPISODE)\n",
    "agent = DQNAgent(env.action_space.n, np.prod(env.observation_space.shape), lr=LEARNING_RATE, gamma=GAMMA, epsilon=EPSILON,\n",
    "                 epsilon_min=EPSILON_MIN, epsilon_decay=EPSILON_DECAY, batch_size=BATCH_SIZE, buffer_size=BUFFER_SIZE)\n",
    "\n",
    "start_episode = 0\n",
    "start_step = 0\n",
    "\n",
    "# Try loading an existing model\n",
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "         start_episode, start_step = agent.load(MODEL_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved model found, starting from scratch.\")\n",
    "\n",
    "# Try loading an existing buffer\n",
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "        agent.buffer.load(BUFFER_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved buffer found, starting with empty buffer.\")\n",
    "\n",
    "\n",
    "for episode in range(start_episode, NUMBER_OF_EPISODES):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "\n",
    "    # Calculate beta for the current training step (frame_idx)\n",
    "    frame_idx = episode * 50 + step  # Adjust this according to your setup\n",
    "    beta = min(1.0, BETA_START + (BEAT_FRAMES - BETA_START) * frame_idx / TOTAL_FRAMES)\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(state)  # Get action from your agent\n",
    "        next_state, reward, done, _ = env.step(action, episode, step)\n",
    "        step += 1\n",
    "        agent.buffer.add((state, action, reward, next_state, float(done)))\n",
    "\n",
    "        print(f\"E{episode} S{step} | reward: {reward:.3f} | epsilon: {agent.epsilon:.3f} | beta: {beta:.3f}\")\n",
    "\n",
    "        agent.train(beta=beta)\n",
    "        # if episode > 2000:\n",
    "        #     time.sleep(0.1)\n",
    "        \n",
    "    # Every 10 episodes, update target network and save model and buffer\n",
    "    if episode % 10 == 0:\n",
    "        agent.update_target_network()\n",
    "        agent.save(MODEL_PATH, episode, step)\n",
    "        agent.buffer.save(BUFFER_PATH)\n",
    "        print(\"Model and Buffer saved.\")\n",
    "        \n",
    "    print(f\"Episode {episode + 1} finished\")\n",
    "\n",
    "# Save the final model and buffer after training is complete\n",
    "agent.save(MODEL_PATH, episode, step)\n",
    "agent.buffer.save(BUFFER_PATH)\n",
    "print(\"Training complete, model and buffer saved.\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b0d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
