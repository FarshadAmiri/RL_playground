{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da542328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fa97993",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode, step = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f49357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Q-Network for DQN Agent\n",
    "# -----------------------------\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_channels, num_actions, grid_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),  # [B, 32, H, W]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),              # [B, 64, H, W]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),              # [B, 64, H, W]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Flatten after conv layers\n",
    "        self.fc_input_size = None  # Placeholder, will be set dynamically\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * grid_size * grid_size, 512),  # Update based on actual grid size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Prioritized Replay Buffer\n",
    "# -----------------------------\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            capacity (int): Maximum number of transitions to store.\n",
    "            alpha (float): How much prioritization is used \n",
    "                           (0 = no prioritization, 1 = full prioritization).\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []             # List to store experiences.\n",
    "        self.priorities = []         # List to store priorities.\n",
    "        self.alpha = alpha\n",
    "        self.pos = 0\n",
    "\n",
    "    def add(self, experience):\n",
    "        \"\"\"Adds an experience to the buffer with maximum priority.\"\"\"\n",
    "        # If the buffer is not full, append the new experience;\n",
    "        # otherwise, replace the oldest one (circular buffer).\n",
    "        max_priority = max(self.priorities) if self.buffer else 1.0\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(experience)\n",
    "            self.priorities.append(max_priority)\n",
    "        else:\n",
    "            self.buffer[self.pos] = experience\n",
    "            self.priorities[self.pos] = max_priority\n",
    "            self.pos = (self.pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        \"\"\"\n",
    "        Samples a batch of experiences with probabilities proportional to their priorities.\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int): Number of samples to draw.\n",
    "            beta (float): Importance-sampling, from initial value increasing to 1.\n",
    "        \n",
    "        Returns:\n",
    "            samples: List of sampled experiences.\n",
    "            indices: The indices of the sampled experiences.\n",
    "            weights: Importance sampling weights for the batch.\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        prios = np.array(self.priorities, dtype=np.float32)\n",
    "        probs = prios ** self.alpha\n",
    "        probs_sum = probs.sum()\n",
    "        if probs_sum == 0 or np.isnan(probs_sum):\n",
    "            probs = np.ones_like(probs) / len(probs)\n",
    "        else:\n",
    "            probs /= probs_sum\n",
    "\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[i] for i in indices]\n",
    "\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()  # Normalize\n",
    "\n",
    "        return samples, indices, weights\n",
    "    \n",
    "\n",
    "    def update_priorities(self, indices, new_priorities):\n",
    "        \"\"\"\n",
    "        Updates the priorities of sampled experiences.\n",
    "        \n",
    "        Args:\n",
    "            indices (list of int): The indices of the experiences to update.\n",
    "            new_priorities (list of float): The new priority for each corresponding experience.\n",
    "        \"\"\"\n",
    "        for idx, priority in zip(indices, new_priorities):\n",
    "            self.priorities[idx] = priority\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump((self.buffer, self.priorities, self.pos), f)\n",
    "        print(f\"Replay buffer saved to {filepath}\")\n",
    "\n",
    "    def load(self, filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            self.buffer, self.priorities, self.pos = pickle.load(f)\n",
    "        print(f\"Replay buffer loaded from {filepath}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DQN Agent\n",
    "# -----------------------------\n",
    "class DQNAgent:\n",
    "    def __init__(self, action_space, state_space, grid_size, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_min=0.1, \n",
    "                 epsilon_decay=0.995, batch_size=64, buffer_size=10000):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.step = 0  # <--- Track steps here\n",
    "\n",
    "        input_channels = 3  # Agent, rewards, enemies\n",
    "\n",
    "        self.q_network = QNetwork(input_channels, action_space, grid_size).to(self.device)\n",
    "        self.target_network = QNetwork(input_channels, action_space, grid_size).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)\n",
    "        self.buffer = PrioritizedReplayBuffer(buffer_size)\n",
    "\n",
    "        self.update_target_network()\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_space)\n",
    "        \n",
    "        # Convert to shape [1, C, H, W] assuming 3-channel input (C=3)\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)  # [1, 3, H, W]\n",
    "        q_values = self.q_network(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, beta=0.4):\n",
    "        if self.buffer.size() < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch, indices, weights = self.buffer.sample(self.batch_size, beta)\n",
    "        if not batch:\n",
    "            return  # Safety check\n",
    "\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        # Convert batch to tensors\n",
    "        # Shape: [B, 3, H, W] assuming 3-channel grid input\n",
    "        states = torch.FloatTensor(np.array(states)).to(self.device)  # [B, 3, H, W]\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(self.device)  # [B, 3, H, W]\n",
    "        actions = torch.LongTensor(actions).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        weights = torch.FloatTensor(weights).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "\n",
    "        # Forward pass\n",
    "        q_values = self.q_network(states).gather(1, actions)  # [B, 1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_network(next_states).max(1, keepdim=True)[0]  # [B, 1]\n",
    "            target_q_values = rewards + self.gamma * next_q_values * (1 - dones)\n",
    "\n",
    "        td_errors = q_values - target_q_values\n",
    "        loss = (weights * td_errors.pow(2)).mean()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update priorities\n",
    "        new_priorities = td_errors.abs().detach().cpu().numpy().flatten() + 1e-6\n",
    "        self.buffer.update_priorities(indices, new_priorities)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save(self, filepath, episode, step):\n",
    "        torch.save({\n",
    "            'policy_net_state_dict': self.q_network.state_dict(),\n",
    "            'target_net_state_dict': self.target_network.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'episode': episode,\n",
    "            'step': step,\n",
    "            'epsilon': self.epsilon\n",
    "        }, filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=self.device)\n",
    "        self.q_network.load_state_dict(checkpoint['policy_net_state_dict'])\n",
    "        self.target_network.load_state_dict(checkpoint['target_net_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        episode = checkpoint.get('episode', 0)\n",
    "        step = checkpoint.get('step', 0)\n",
    "        self.epsilon = checkpoint.get('epsilon', 1.0)\n",
    "        print(f\"Loaded model from {filepath} | episode: {episode} | step: {step} | epsilon: {self.epsilon:.4f}\")\n",
    "        return episode, step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0069e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Collect & Avoid Environment (gym.Env subclass)\n",
    "# -------------------------------------------\n",
    "\n",
    "class CollectAvoidEnv(gym.Env):\n",
    "    def __init__(self, grid_size=15, num_rewards=5, num_enemies=3, enemy_random_move_ratio=0.5, max_steps=1000):\n",
    "        super(CollectAvoidEnv, self).__init__()\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "        self.num_rewards = num_rewards\n",
    "        self.num_enemies = num_enemies\n",
    "        self.enemy_random_move_ratio = enemy_random_move_ratio\n",
    "        self.reward_positions = []\n",
    "        self.enemy_positions = []\n",
    "        self.agent_pos = None\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Action space: 5 discrete actions\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "\n",
    "        # Observation space: 3-channel grid (agent, rewards, enemies)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0.0, high=1.0,\n",
    "            shape=(3, self.grid_size, self.grid_size),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Plotting setup\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 6))\n",
    "        self.ax.set_xlim(0, self.grid_size - 1)\n",
    "        self.ax.set_ylim(0, self.grid_size - 1)\n",
    "        self.ax.set_xticks(range(self.grid_size))\n",
    "        self.ax.set_yticks(range(self.grid_size))\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.reward_positions = [self._random_empty_cell([]) for _ in range(self.num_rewards)]\n",
    "        self.enemy_positions = [self._random_empty_cell(self.reward_positions) for _ in range(self.num_enemies)]\n",
    "        self.agent_pos = self._random_empty_cell(self.reward_positions + self.enemy_positions)\n",
    "        self.current_step = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def step(self, action, episode, step):\n",
    "        self.current_step += 1\n",
    "        prev_agent_pos = self.agent_pos\n",
    "\n",
    "        # Move agent\n",
    "        if action == 0:  # stay\n",
    "            new_pos = self.agent_pos\n",
    "        elif action == 1:  # up\n",
    "            new_pos = (max(self.agent_pos[0] - 1, 0), self.agent_pos[1])\n",
    "        elif action == 2:  # down\n",
    "            new_pos = (min(self.agent_pos[0] + 1, self.grid_size - 1), self.agent_pos[1])\n",
    "        elif action == 3:  # left\n",
    "            new_pos = (self.agent_pos[0], max(self.agent_pos[1] - 1, 0))\n",
    "        elif action == 4:  # right\n",
    "            new_pos = (self.agent_pos[0], min(self.agent_pos[1] + 1, self.grid_size - 1))\n",
    "\n",
    "        self.agent_pos = new_pos\n",
    "\n",
    "        # Move enemies\n",
    "        self._move_enemies()\n",
    "\n",
    "        # Compute reward and check if agent is caught by an enemy or has collected all rewards\n",
    "        reward = self._compute_reward(prev_agent_pos)\n",
    "        done = self.agent_pos in self.enemy_positions or len(self.reward_positions) == 0 or self.current_step >= self.max_steps # Terminate if caught by enemy or all rewards are collected\n",
    "\n",
    "        # Render environment\n",
    "        self.render(episode, step, reward)\n",
    "        return self._get_state(), reward, done, {}\n",
    "\n",
    "    def _get_state(self):\n",
    "        state = np.zeros((3, self.grid_size, self.grid_size), dtype=np.float32)\n",
    "\n",
    "        # Agent in channel 0\n",
    "        state[0, self.agent_pos[0], self.agent_pos[1]] = 1.0\n",
    "\n",
    "        # Rewards in channel 1\n",
    "        for r in self.reward_positions:\n",
    "            state[1, r[0], r[1]] = 1.0\n",
    "\n",
    "        # Enemies in channel 2\n",
    "        for e in self.enemy_positions:\n",
    "            state[2, e[0], e[1]] = 1.0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _compute_reward(self, prev_agent_pos):\n",
    "        reward = 0.0\n",
    "\n",
    "        if self.agent_pos in self.reward_positions:\n",
    "            self.reward_positions.remove(self.agent_pos)\n",
    "            reward += 3.0\n",
    "\n",
    "        # Reward for being near remaining rewards\n",
    "        for rx, ry in self.reward_positions:\n",
    "            dist = abs(self.agent_pos[0] - rx) + abs(self.agent_pos[1] - ry)\n",
    "            if dist == 1: reward += 0.2\n",
    "            elif dist == 2: reward += 0.15\n",
    "            elif dist == 3: reward += 0.1\n",
    "\n",
    "        # Penalty for being near enemies\n",
    "        for ex, ey in self.enemy_positions:\n",
    "            edist = abs(self.agent_pos[0] - ex) + abs(self.agent_pos[1] - ey)\n",
    "            if edist == 1: reward -= 1\n",
    "            elif edist == 2: reward -= 0.5\n",
    "            elif edist == 3: reward -= 0.3\n",
    "            elif edist == 4: reward -= 0.2\n",
    "\n",
    "        # Reward for increasing distance from enemies\n",
    "        if self.enemy_positions:\n",
    "            prev_avg = np.mean([abs(prev_agent_pos[0] - ex) + abs(prev_agent_pos[1] - ey) for ex, ey in self.enemy_positions])\n",
    "            curr_avg = np.mean([abs(self.agent_pos[0] - ex) + abs(self.agent_pos[1] - ey) for ex, ey in self.enemy_positions])\n",
    "            if curr_avg > prev_avg: reward += 0.3\n",
    "            elif curr_avg < prev_avg: reward -= 0.3\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def _move_enemies(self):\n",
    "        for i in range(len(self.enemy_positions)):\n",
    "            x, y = self.enemy_positions[i]\n",
    "            ax, ay = self.agent_pos\n",
    "\n",
    "            if random.random() < (1 - self.enemy_random_move_ratio):\n",
    "                if ax > x: x += 1\n",
    "                elif ax < x: x -= 1\n",
    "                if ay > y: y += 1\n",
    "                elif ay < y: y -= 1\n",
    "            else:\n",
    "                dx, dy = random.choice([(0, 1), (1, 0), (0, -1), (-1, 0)])\n",
    "                x = max(0, min(self.grid_size - 1, x + dx))\n",
    "                y = max(0, min(self.grid_size - 1, y + dy))\n",
    "\n",
    "            self.enemy_positions[i] = (x, y)\n",
    "\n",
    "    def _random_empty_cell(self, excluded_cells):\n",
    "        while True:\n",
    "            cell = (random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1))\n",
    "            if cell not in excluded_cells:\n",
    "                return cell\n",
    "\n",
    "    def render(self, episode, step, reward=None):\n",
    "        self.ax.clear()\n",
    "        self.ax.set_xlim(0, self.grid_size - 1)\n",
    "        self.ax.set_ylim(0, self.grid_size - 1)\n",
    "        self.ax.set_xticks(range(self.grid_size))\n",
    "        self.ax.set_yticks(range(self.grid_size))\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.ax.plot(self.agent_pos[0], self.agent_pos[1], 'bo', markersize=10)\n",
    "        for r_pos in self.reward_positions:\n",
    "            self.ax.plot(r_pos[0], r_pos[1], 'go', markersize=10)\n",
    "        for e_pos in self.enemy_positions:\n",
    "            self.ax.plot(e_pos[0], e_pos[1], 'ro', markersize=10)\n",
    "\n",
    "        self.ax.text(0.5, self.grid_size - 1, f'Episode: {episode}, Step: {step}',\n",
    "                     horizontalalignment='center', verticalalignment='top', fontsize=12, color='black', weight='bold')\n",
    "\n",
    "        if reward is not None:\n",
    "            reward_color = 'green' if reward > 0 else 'red' if reward < 0 else 'black'\n",
    "            self.ax.text(0.5, self.grid_size - 2, f'Reward: {reward:.2f}',\n",
    "                         horizontalalignment='center', verticalalignment='top', fontsize=12, color=reward_color, weight='bold')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(self.fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e20c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m     63\u001b[39m     action = agent.act(state)  \u001b[38;5;66;03m# Get action from your agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     next_state, reward, done, _ = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     step += \u001b[32m1\u001b[39m\n\u001b[32m     66\u001b[39m     agent.buffer.add((state, action, reward, next_state, \u001b[38;5;28mfloat\u001b[39m(done)))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mCollectAvoidEnv.step\u001b[39m\u001b[34m(self, action, episode, step)\u001b[39m\n\u001b[32m     69\u001b[39m done = \u001b[38;5;28mself\u001b[39m.agent_pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enemy_positions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.reward_positions) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_step >= \u001b[38;5;28mself\u001b[39m.max_steps \u001b[38;5;66;03m# Terminate if caught by enemy or all rewards are collected\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Render environment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_state(), reward, done, {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 168\u001b[39m, in \u001b[36mCollectAvoidEnv.render\u001b[39m\u001b[34m(self, episode, step, reward)\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28mself\u001b[39m.ax.text(\u001b[32m0.5\u001b[39m, \u001b[38;5;28mself\u001b[39m.grid_size - \u001b[32m2\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mReward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m    165\u001b[39m                  horizontalalignment=\u001b[33m'\u001b[39m\u001b[33mcenter\u001b[39m\u001b[33m'\u001b[39m, verticalalignment=\u001b[33m'\u001b[39m\u001b[33mtop\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m12\u001b[39m, color=reward_color, weight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    167\u001b[39m clear_output(wait=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\IPython\\core\\display_functions.py:278\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     publish_display_data(data=obj, metadata=metadata, **kwargs)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     format_dict, md_dict = \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[32m    280\u001b[39m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\IPython\\core\\formatters.py:238\u001b[39m, in \u001b[36mDisplayFormatter.format\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m    236\u001b[39m md = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     data = \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\IPython\\core\\formatters.py:282\u001b[39m, in \u001b[36mcatch_format_error\u001b[39m\u001b[34m(method, self, *args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     r = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\IPython\\core\\formatters.py:402\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[32m    404\u001b[39m method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170\u001b[39m, in \u001b[36mprint_figure\u001b[39m\u001b[34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[32m    168\u001b[39m     FigureCanvasBase(fig)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m data = bytes_io.getvalue()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fmt == \u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\backend_bases.py:2184\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2181\u001b[39m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[32m   2182\u001b[39m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[32m   2183\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(\u001b[38;5;28mself\u001b[39m.figure, dpi=dpi):\n\u001b[32m-> \u001b[39m\u001b[32m2184\u001b[39m         result = \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2185\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\backend_bases.py:2040\u001b[39m, in \u001b[36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2036\u001b[39m     optional_kws = {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[32m   2037\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2038\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbbox_inches_restore\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   2039\u001b[39m     skip = optional_kws - {*inspect.signature(meth).parameters}\n\u001b[32m-> \u001b[39m\u001b[32m2040\u001b[39m     print_method = functools.wraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2042\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[32m   2043\u001b[39m     print_method = meth\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:481\u001b[39m, in \u001b[36mFigureCanvasAgg.print_png\u001b[39m\u001b[34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[33;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    479\u001b[39m \u001b[33;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:429\u001b[39m, in \u001b[36mFigureCanvasAgg._print_pil\u001b[39m\u001b[34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    425\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     mpl.image.imsave(\n\u001b[32m    431\u001b[39m         filename_or_obj, \u001b[38;5;28mself\u001b[39m.buffer_rgba(), \u001b[38;5;28mformat\u001b[39m=fmt, origin=\u001b[33m\"\u001b[39m\u001b[33mupper\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m         dpi=\u001b[38;5;28mself\u001b[39m.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:382\u001b[39m, in \u001b[36mFigureCanvasAgg.draw\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.toolbar._wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.toolbar\n\u001b[32m    381\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28msuper\u001b[39m().draw()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:94\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     96\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\figure.py:3257\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3254\u001b[39m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   3256\u001b[39m     \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3257\u001b[39m     \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3260\u001b[39m     renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axes\\_base.py:3210\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[32m   3208\u001b[39m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3210\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3213\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3214\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:1408\u001b[39m, in \u001b[36mAxis.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   1405\u001b[39m tlb1, tlb2 = \u001b[38;5;28mself\u001b[39m._get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[32m-> \u001b[39m\u001b[32m1408\u001b[39m     \u001b[43mtick\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[38;5;66;03m# Shift label away from axes to avoid overlapping ticklabels.\u001b[39;00m\n\u001b[32m   1411\u001b[39m \u001b[38;5;28mself\u001b[39m._update_label_position(renderer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:276\u001b[39m, in \u001b[36mTick.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    273\u001b[39m renderer.open_group(\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m, gid=\u001b[38;5;28mself\u001b[39m.get_gid())\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m artist \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.gridline, \u001b[38;5;28mself\u001b[39m.tick1line, \u001b[38;5;28mself\u001b[39m.tick2line,\n\u001b[32m    275\u001b[39m                \u001b[38;5;28mself\u001b[39m.label1, \u001b[38;5;28mself\u001b[39m.label2]:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[43martist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m renderer.close_group(\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m    278\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\text.py:808\u001b[39m, in \u001b[36mText.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    804\u001b[39m             textrenderer.draw_tex(gc, x, y, clean_line,\n\u001b[32m    805\u001b[39m                                   \u001b[38;5;28mself\u001b[39m._fontproperties, angle,\n\u001b[32m    806\u001b[39m                                   mtext=mtext)\n\u001b[32m    807\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m             \u001b[43mtextrenderer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_line\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fontproperties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    812\u001b[39m gc.restore()\n\u001b[32m    813\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:192\u001b[39m, in \u001b[36mRendererAgg.draw_text\u001b[39m\u001b[34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[39m\n\u001b[32m    189\u001b[39m font = \u001b[38;5;28mself\u001b[39m._prepare_font(prop)\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# We pass '0' for angle here, since it will be rotated (in raster\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# space) in the following call to draw_text_image).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m \u001b[43mfont\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_hinting_flag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m font.draw_glyphs_to_bitmap(\n\u001b[32m    194\u001b[39m     antialiased=gc.get_antialiased())\n\u001b[32m    195\u001b[39m d = font.get_descent() / \u001b[32m64.0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Train the Agent\n",
    "# -------------------------------------------\n",
    "\n",
    "\"\"\" Input Variables \"\"\"\n",
    "GRID_SIZE = 30\n",
    "NUM_REWARDS = 12\n",
    "NUM_ENEMIES = 1\n",
    "ENEMY_RANDOM_MOVE_RATIO = 0.6\n",
    "NUMBER_OF_EPISODES = 10000\n",
    "MAX_STEPS_PER_EPISODE= 700\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.95  # 0: only immediate reward matters ; 1.0: future rewards are just as important as immediate ones.\n",
    "EPSILON = 1.0   # initial value for weighting random over policy in taking actions\n",
    "EPSILON_MIN = 0.2\n",
    "EPSILON_DECAY = 0.9999  # multiplies random action chance with this factor after every training\n",
    "BATCH_SIZE = 8  # number of samples to take from the replay buffer for training\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# Define the annealing parameters for beta (Prioritized Replay Buffer)\n",
    "BETA_START = 0.4  # Starting value for beta (usually smaller)\n",
    "BEAT_FRAMES = 10  # Number of frames after which beta will reach 1.0\n",
    "TOTAL_FRAMES = NUMBER_OF_EPISODES * 100  # Total frames in the training\n",
    "\n",
    "RESUME_TRAINING = False\n",
    "MODEL_PATH = r\"E:\\Git_repos\\RL_playground\\CollectAndAvoid\\trained_models\\cnn_models\\dqn_cnn_model_1.pth\"\n",
    "BUFFER_PATH = r\"E:\\Git_repos\\RL_playground\\CollectAndAvoid\\trained_models\\cnn_models\\buffer_CNN_1.pth\"\n",
    "\"\"\" END of Input Variables \"\"\"\n",
    "\n",
    "env = CollectAvoidEnv(grid_size=GRID_SIZE, num_rewards=NUM_REWARDS, num_enemies=NUM_ENEMIES, enemy_random_move_ratio=ENEMY_RANDOM_MOVE_RATIO, max_steps=MAX_STEPS_PER_EPISODE)\n",
    "agent = DQNAgent(env.action_space.n, np.prod(env.observation_space.shape), GRID_SIZE, lr=LEARNING_RATE, gamma=GAMMA, epsilon=EPSILON,\n",
    "                 epsilon_min=EPSILON_MIN, epsilon_decay=EPSILON_DECAY, batch_size=BATCH_SIZE, buffer_size=BUFFER_SIZE)\n",
    "\n",
    "start_episode = 0\n",
    "start_step = 0\n",
    "\n",
    "# Try loading an existing model\n",
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "         start_episode, start_step = agent.load(MODEL_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved model found, starting from scratch.\")\n",
    "\n",
    "# Try loading an existing buffer\n",
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "        agent.buffer.load(BUFFER_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved buffer found, starting with empty buffer.\")\n",
    "\n",
    "\n",
    "for episode in range(start_episode, NUMBER_OF_EPISODES):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "\n",
    "    # Calculate beta for the current training step (frame_idx)\n",
    "    frame_idx = episode * 50 + step  # Adjust this according to your setup\n",
    "    beta = min(1.0, BETA_START + (BEAT_FRAMES - BETA_START) * frame_idx / TOTAL_FRAMES)\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(state)  # Get action from your agent\n",
    "        next_state, reward, done, _ = env.step(action, episode, step)\n",
    "        step += 1\n",
    "        agent.buffer.add((state, action, reward, next_state, float(done)))\n",
    "\n",
    "        print(f\"E{episode} S{step} | reward: {reward:.3f} | epsilon: {agent.epsilon:.3f} | beta: {beta:.3f}\")\n",
    "\n",
    "        agent.train(beta=beta)\n",
    "        # if episode > 2000:\n",
    "        #     time.sleep(0.1)\n",
    "        \n",
    "    # Every 10 episodes, update target network and save model and buffer\n",
    "    if episode % 10 == 0:\n",
    "        agent.update_target_network()\n",
    "        agent.save(MODEL_PATH, episode, step)\n",
    "        agent.buffer.save(BUFFER_PATH)\n",
    "        print(\"Model and Buffer saved.\")\n",
    "        \n",
    "    print(f\"Episode {episode + 1} finished\")\n",
    "\n",
    "# Save the final model and buffer after training is complete\n",
    "agent.save(MODEL_PATH, episode, step)\n",
    "agent.buffer.save(BUFFER_PATH)\n",
    "print(\"Training complete, model and buffer saved.\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b0d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
