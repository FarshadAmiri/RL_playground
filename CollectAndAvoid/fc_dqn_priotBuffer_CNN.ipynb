{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da542328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa97993",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode, step = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f49357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Q-Network for DQN Agent\n",
    "# -----------------------------\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_channels, num_actions):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),  # [B, 32, H, W]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),              # [B, 64, H, W]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),              # [B, 64, H, W]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Flatten after conv layers\n",
    "        self.fc_input_size = None  # Placeholder, will be set dynamically\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 15 * 15, 512),  # Update based on actual grid size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Prioritized Replay Buffer\n",
    "# -----------------------------\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            capacity (int): Maximum number of transitions to store.\n",
    "            alpha (float): How much prioritization is used \n",
    "                           (0 = no prioritization, 1 = full prioritization).\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []             # List to store experiences.\n",
    "        self.priorities = []         # List to store priorities.\n",
    "        self.alpha = alpha\n",
    "        self.pos = 0\n",
    "\n",
    "    def add(self, experience):\n",
    "        \"\"\"Adds an experience to the buffer with maximum priority.\"\"\"\n",
    "        # If the buffer is not full, append the new experience;\n",
    "        # otherwise, replace the oldest one (circular buffer).\n",
    "        max_priority = max(self.priorities) if self.buffer else 1.0\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(experience)\n",
    "            self.priorities.append(max_priority)\n",
    "        else:\n",
    "            self.buffer[self.pos] = experience\n",
    "            self.priorities[self.pos] = max_priority\n",
    "            self.pos = (self.pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        \"\"\"\n",
    "        Samples a batch of experiences with probabilities proportional to their priorities.\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int): Number of samples to draw.\n",
    "            beta (float): Importance-sampling, from initial value increasing to 1.\n",
    "        \n",
    "        Returns:\n",
    "            samples: List of sampled experiences.\n",
    "            indices: The indices of the sampled experiences.\n",
    "            weights: Importance sampling weights for the batch.\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        prios = np.array(self.priorities, dtype=np.float32)\n",
    "        probs = prios ** self.alpha\n",
    "        probs_sum = probs.sum()\n",
    "        if probs_sum == 0 or np.isnan(probs_sum):\n",
    "            probs = np.ones_like(probs) / len(probs)\n",
    "        else:\n",
    "            probs /= probs_sum\n",
    "\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[i] for i in indices]\n",
    "\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()  # Normalize\n",
    "\n",
    "        return samples, indices, weights\n",
    "    \n",
    "\n",
    "    def update_priorities(self, indices, new_priorities):\n",
    "        \"\"\"\n",
    "        Updates the priorities of sampled experiences.\n",
    "        \n",
    "        Args:\n",
    "            indices (list of int): The indices of the experiences to update.\n",
    "            new_priorities (list of float): The new priority for each corresponding experience.\n",
    "        \"\"\"\n",
    "        for idx, priority in zip(indices, new_priorities):\n",
    "            self.priorities[idx] = priority\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump((self.buffer, self.priorities, self.pos), f)\n",
    "        print(f\"Replay buffer saved to {filepath}\")\n",
    "\n",
    "    def load(self, filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            self.buffer, self.priorities, self.pos = pickle.load(f)\n",
    "        print(f\"Replay buffer loaded from {filepath}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DQN Agent\n",
    "# -----------------------------\n",
    "class DQNAgent:\n",
    "    def __init__(self, action_space, state_space, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_min=0.1, \n",
    "                 epsilon_decay=0.995, batch_size=64, buffer_size=10000):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.step = 0  # <--- Track steps here\n",
    "\n",
    "        input_channels = 3  # Agent, rewards, enemies\n",
    "\n",
    "        self.q_network = QNetwork(input_channels, action_space).to(self.device)\n",
    "        self.target_network = QNetwork(input_channels, action_space).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)\n",
    "        self.buffer = PrioritizedReplayBuffer(buffer_size)\n",
    "\n",
    "        self.update_target_network()\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.action_space)\n",
    "        \n",
    "        # Convert to shape [1, C, H, W] assuming 3-channel input (C=3)\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)  # [1, 3, H, W]\n",
    "        q_values = self.q_network(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, beta=0.4):\n",
    "        if self.buffer.size() < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch, indices, weights = self.buffer.sample(self.batch_size, beta)\n",
    "        if not batch:\n",
    "            return  # Safety check\n",
    "\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        # Convert batch to tensors\n",
    "        # Shape: [B, 3, H, W] assuming 3-channel grid input\n",
    "        states = torch.FloatTensor(np.array(states)).to(self.device)  # [B, 3, H, W]\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(self.device)  # [B, 3, H, W]\n",
    "        actions = torch.LongTensor(actions).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "        weights = torch.FloatTensor(weights).unsqueeze(1).to(self.device)  # [B, 1]\n",
    "\n",
    "        # Forward pass\n",
    "        q_values = self.q_network(states).gather(1, actions)  # [B, 1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_q_values = self.target_network(next_states).max(1, keepdim=True)[0]  # [B, 1]\n",
    "            target_q_values = rewards + self.gamma * next_q_values * (1 - dones)\n",
    "\n",
    "        td_errors = q_values - target_q_values\n",
    "        loss = (weights * td_errors.pow(2)).mean()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update priorities\n",
    "        new_priorities = td_errors.abs().detach().cpu().numpy().flatten() + 1e-6\n",
    "        self.buffer.update_priorities(indices, new_priorities)\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save(self, filepath, episode, step):\n",
    "        torch.save({\n",
    "            'policy_net_state_dict': self.q_network.state_dict(),\n",
    "            'target_net_state_dict': self.target_network.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'episode': episode,\n",
    "            'step': step,\n",
    "            'epsilon': self.epsilon\n",
    "        }, filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        checkpoint = torch.load(filepath, map_location=self.device)\n",
    "        self.q_network.load_state_dict(checkpoint['policy_net_state_dict'])\n",
    "        self.target_network.load_state_dict(checkpoint['target_net_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        episode = checkpoint.get('episode', 0)\n",
    "        step = checkpoint.get('step', 0)\n",
    "        self.epsilon = checkpoint.get('epsilon', 1.0)\n",
    "        print(f\"Loaded model from {filepath} | episode: {episode} | step: {step} | epsilon: {self.epsilon:.4f}\")\n",
    "        return episode, step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0069e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Collect & Avoid Environment (gym.Env subclass)\n",
    "# -------------------------------------------\n",
    "\n",
    "class CollectAvoidEnv(gym.Env):\n",
    "    def __init__(self, grid_size=15, num_rewards=5, num_enemies=3, enemy_random_move_ratio=0.5):\n",
    "        super(CollectAvoidEnv, self).__init__()\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "        self.num_rewards = num_rewards\n",
    "        self.num_enemies = num_enemies\n",
    "        self.enemy_random_move_ratio = enemy_random_move_ratio\n",
    "        self.reward_positions = []\n",
    "        self.enemy_positions = []\n",
    "        self.agent_pos = None\n",
    "\n",
    "        # Action space: 5 discrete actions\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "\n",
    "        # Observation space: 3-channel grid (agent, rewards, enemies)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0.0, high=1.0,\n",
    "            shape=(3, self.grid_size, self.grid_size),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Plotting setup\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 6))\n",
    "        self.ax.set_xlim(0, self.grid_size - 1)\n",
    "        self.ax.set_ylim(0, self.grid_size - 1)\n",
    "        self.ax.set_xticks(range(self.grid_size))\n",
    "        self.ax.set_yticks(range(self.grid_size))\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.reward_positions = [self._random_empty_cell([]) for _ in range(self.num_rewards)]\n",
    "        self.enemy_positions = [self._random_empty_cell(self.reward_positions) for _ in range(self.num_enemies)]\n",
    "        self.agent_pos = self._random_empty_cell(self.reward_positions + self.enemy_positions)\n",
    "        return self._get_state()\n",
    "\n",
    "    def step(self, action, episode, step):\n",
    "        prev_agent_pos = self.agent_pos\n",
    "\n",
    "        # Move agent\n",
    "        if action == 0:  # stay\n",
    "            new_pos = self.agent_pos\n",
    "        elif action == 1:  # up\n",
    "            new_pos = (max(self.agent_pos[0] - 1, 0), self.agent_pos[1])\n",
    "        elif action == 2:  # down\n",
    "            new_pos = (min(self.agent_pos[0] + 1, self.grid_size - 1), self.agent_pos[1])\n",
    "        elif action == 3:  # left\n",
    "            new_pos = (self.agent_pos[0], max(self.agent_pos[1] - 1, 0))\n",
    "        elif action == 4:  # right\n",
    "            new_pos = (self.agent_pos[0], min(self.agent_pos[1] + 1, self.grid_size - 1))\n",
    "\n",
    "        self.agent_pos = new_pos\n",
    "\n",
    "        # Move enemies\n",
    "        self._move_enemies()\n",
    "\n",
    "        # Compute reward and check if agent is caught by an enemy or has collected all rewards\n",
    "        reward = self._compute_reward(prev_agent_pos)\n",
    "        done = self.agent_pos in self.enemy_positions or len(self.reward_positions) == 0  # Terminate if caught by enemy or all rewards are collected\n",
    "\n",
    "        # Render environment\n",
    "        self.render(episode, step, reward)\n",
    "        return self._get_state(), reward, done, {}\n",
    "\n",
    "    def _get_state(self):\n",
    "        state = np.zeros((3, self.grid_size, self.grid_size), dtype=np.float32)\n",
    "\n",
    "        # Agent in channel 0\n",
    "        state[0, self.agent_pos[0], self.agent_pos[1]] = 1.0\n",
    "\n",
    "        # Rewards in channel 1\n",
    "        for r in self.reward_positions:\n",
    "            state[1, r[0], r[1]] = 1.0\n",
    "\n",
    "        # Enemies in channel 2\n",
    "        for e in self.enemy_positions:\n",
    "            state[2, e[0], e[1]] = 1.0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _compute_reward(self, prev_agent_pos):\n",
    "        reward = 0.0\n",
    "\n",
    "        if self.agent_pos in self.reward_positions:\n",
    "            self.reward_positions.remove(self.agent_pos)\n",
    "            reward += 3.0\n",
    "\n",
    "        # Reward for being near remaining rewards\n",
    "        for rx, ry in self.reward_positions:\n",
    "            dist = abs(self.agent_pos[0] - rx) + abs(self.agent_pos[1] - ry)\n",
    "            if dist == 1: reward += 0.2\n",
    "            elif dist == 2: reward += 0.15\n",
    "            elif dist == 3: reward += 0.1\n",
    "\n",
    "        # Penalty for being near enemies\n",
    "        for ex, ey in self.enemy_positions:\n",
    "            edist = abs(self.agent_pos[0] - ex) + abs(self.agent_pos[1] - ey)\n",
    "            if edist == 1: reward -= 1\n",
    "            elif edist == 2: reward -= 0.5\n",
    "            elif edist == 3: reward -= 0.3\n",
    "            elif edist == 4: reward -= 0.2\n",
    "\n",
    "        # Reward for increasing distance from enemies\n",
    "        if self.enemy_positions:\n",
    "            prev_avg = np.mean([abs(prev_agent_pos[0] - ex) + abs(prev_agent_pos[1] - ey) for ex, ey in self.enemy_positions])\n",
    "            curr_avg = np.mean([abs(self.agent_pos[0] - ex) + abs(self.agent_pos[1] - ey) for ex, ey in self.enemy_positions])\n",
    "            if curr_avg > prev_avg: reward += 0.3\n",
    "            elif curr_avg < prev_avg: reward -= 0.3\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def _move_enemies(self):\n",
    "        for i in range(len(self.enemy_positions)):\n",
    "            x, y = self.enemy_positions[i]\n",
    "            ax, ay = self.agent_pos\n",
    "\n",
    "            if random.random() < (1 - self.enemy_random_move_ratio):\n",
    "                if ax > x: x += 1\n",
    "                elif ax < x: x -= 1\n",
    "                if ay > y: y += 1\n",
    "                elif ay < y: y -= 1\n",
    "            else:\n",
    "                dx, dy = random.choice([(0, 1), (1, 0), (0, -1), (-1, 0)])\n",
    "                x = max(0, min(self.grid_size - 1, x + dx))\n",
    "                y = max(0, min(self.grid_size - 1, y + dy))\n",
    "\n",
    "            self.enemy_positions[i] = (x, y)\n",
    "\n",
    "    def _random_empty_cell(self, excluded_cells):\n",
    "        while True:\n",
    "            cell = (random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1))\n",
    "            if cell not in excluded_cells:\n",
    "                return cell\n",
    "\n",
    "    def render(self, episode, step, reward=None):\n",
    "        self.ax.clear()\n",
    "        self.ax.set_xlim(0, self.grid_size - 1)\n",
    "        self.ax.set_ylim(0, self.grid_size - 1)\n",
    "        self.ax.set_xticks(range(self.grid_size))\n",
    "        self.ax.set_yticks(range(self.grid_size))\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.ax.plot(self.agent_pos[0], self.agent_pos[1], 'bo', markersize=10)\n",
    "        for r_pos in self.reward_positions:\n",
    "            self.ax.plot(r_pos[0], r_pos[1], 'go', markersize=10)\n",
    "        for e_pos in self.enemy_positions:\n",
    "            self.ax.plot(e_pos[0], e_pos[1], 'ro', markersize=10)\n",
    "\n",
    "        self.ax.text(0.5, self.grid_size - 1, f'Episode: {episode}, Step: {step}',\n",
    "                     horizontalalignment='center', verticalalignment='top', fontsize=12, color='black', weight='bold')\n",
    "\n",
    "        if reward is not None:\n",
    "            reward_color = 'green' if reward > 0 else 'red' if reward < 0 else 'black'\n",
    "            self.ax.text(0.5, self.grid_size - 2, f'Reward: {reward:.2f}',\n",
    "                         horizontalalignment='center', verticalalignment='top', fontsize=12, color=reward_color, weight='bold')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(self.fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e20c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0 S1 | reward: 0.000 | epsilon: 1.000 | beta: 0.400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m     62\u001b[39m     action = agent.act(state)  \u001b[38;5;66;03m# Get action from your agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     next_state, reward, done, _ = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     step += \u001b[32m1\u001b[39m\n\u001b[32m     65\u001b[39m     agent.buffer.add((state, action, reward, next_state, \u001b[38;5;28mfloat\u001b[39m(done)))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mCollectAvoidEnv.step\u001b[39m\u001b[34m(self, action, episode, step)\u001b[39m\n\u001b[32m     65\u001b[39m done = \u001b[38;5;28mself\u001b[39m.agent_pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enemy_positions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.reward_positions) == \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# Terminate if caught by enemy or all rewards are collected\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Render environment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_state(), reward, done, {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 146\u001b[39m, in \u001b[36mCollectAvoidEnv.render\u001b[39m\u001b[34m(self, episode, step, reward)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28mself\u001b[39m.ax.set_ylim(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m.grid_size - \u001b[32m1\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28mself\u001b[39m.ax.set_xticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.grid_size))\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_yticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[38;5;28mself\u001b[39m.ax.grid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.ax.plot(\u001b[38;5;28mself\u001b[39m.agent_pos[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.agent_pos[\u001b[32m1\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mbo\u001b[39m\u001b[33m'\u001b[39m, markersize=\u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axes\\_base.py:74\u001b[39m, in \u001b[36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:2218\u001b[39m, in \u001b[36mAxis.set_ticks\u001b[39m\u001b[34m(self, ticks, labels, minor, **kwargs)\u001b[39m\n\u001b[32m   2213\u001b[39m     first_key = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\n\u001b[32m   2214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2215\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncorrect use of keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_key\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m. Keyword arguments \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mother than \u001b[39m\u001b[33m'\u001b[39m\u001b[33mminor\u001b[39m\u001b[33m'\u001b[39m\u001b[33m modify the text labels and can only be used if \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m\u001b[33m are passed as well.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2218\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_tick_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2220\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_ticklabels(labels, minor=minor, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:2170\u001b[39m, in \u001b[36mAxis._set_tick_locations\u001b[39m\u001b[34m(self, ticks, minor)\u001b[39m\n\u001b[32m   2168\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2169\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_major_locator(locator)\n\u001b[32m-> \u001b[39m\u001b[32m2170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_major_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mticks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:1664\u001b[39m, in \u001b[36mAxis.get_major_ticks\u001b[39m\u001b[34m(self, numticks)\u001b[39m\n\u001b[32m   1660\u001b[39m     numticks = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.get_majorticklocs())\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.majorTicks) < numticks:\n\u001b[32m   1663\u001b[39m     \u001b[38;5;66;03m# Update the new tick label properties from the old.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1664\u001b[39m     tick = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1665\u001b[39m     \u001b[38;5;28mself\u001b[39m.majorTicks.append(tick)\n\u001b[32m   1666\u001b[39m     \u001b[38;5;28mself\u001b[39m._copy_tick_props(\u001b[38;5;28mself\u001b[39m.majorTicks[\u001b[32m0\u001b[39m], tick)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:1592\u001b[39m, in \u001b[36mAxis._get_tick\u001b[39m\u001b[34m(self, major)\u001b[39m\n\u001b[32m   1588\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1589\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe Axis subclass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must define \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1590\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_tick_class or reimplement _get_tick()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1591\u001b[39m tick_kw = \u001b[38;5;28mself\u001b[39m._major_tick_kw \u001b[38;5;28;01mif\u001b[39;00m major \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._minor_tick_kw\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tick_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtick_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:429\u001b[39m, in \u001b[36mYTick.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     \u001b[38;5;66;03m# x in axes coords, y in data coords\u001b[39;00m\n\u001b[32m    431\u001b[39m     ax = \u001b[38;5;28mself\u001b[39m.axes\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\axis.py:154\u001b[39m, in \u001b[36mTick.__init__\u001b[39m\u001b[34m(self, axes, loc, size, width, color, tickdir, pad, labelsize, labelcolor, labelfontfamily, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     grid_alpha = mpl.rcParams[\u001b[33m\"\u001b[39m\u001b[33mgrid.alpha\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    152\u001b[39m grid_kw = {k[\u001b[32m5\u001b[39m:]: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items()}\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28mself\u001b[39m.tick1line = \u001b[43mmlines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLine2D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinestyle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzorder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzorder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisible\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtick1On\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmarkeredgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkersize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkeredgewidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.tick2line = mlines.Line2D(\n\u001b[32m    160\u001b[39m     [], [],\n\u001b[32m    161\u001b[39m     color=color, linestyle=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m, zorder=zorder, visible=tick2On,\n\u001b[32m    162\u001b[39m     markeredgecolor=color, markersize=size, markeredgewidth=width,\n\u001b[32m    163\u001b[39m )\n\u001b[32m    164\u001b[39m \u001b[38;5;28mself\u001b[39m.gridline = mlines.Line2D(\n\u001b[32m    165\u001b[39m     [], [],\n\u001b[32m    166\u001b[39m     color=grid_color, alpha=grid_alpha, visible=gridOn,\n\u001b[32m    167\u001b[39m     linestyle=grid_linestyle, linewidth=grid_linewidth, marker=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    168\u001b[39m     **grid_kw,\n\u001b[32m    169\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\lines.py:407\u001b[39m, in \u001b[36mLine2D.__init__\u001b[39m\u001b[34m(self, xdata, ydata, linewidth, linestyle, color, gapcolor, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28mself\u001b[39m.set_markeredgewidth(markeredgewidth)\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# update kwargs before updating data to give the caller a\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;66;03m# chance to init axes (and hence unit support)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28mself\u001b[39m.pickradius = pickradius\n\u001b[32m    409\u001b[39m \u001b[38;5;28mself\u001b[39m.ind_offset = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:1233\u001b[39m, in \u001b[36mArtist._internal_update\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m   1226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[32m   1227\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1228\u001b[39m \u001b[33;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[32m   1229\u001b[39m \u001b[33;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[32m   1230\u001b[39m \n\u001b[32m   1231\u001b[39m \u001b[33;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[33;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:1209\u001b[39m, in \u001b[36mArtist._update_props\u001b[39m\u001b[34m(self, props, errfmt)\u001b[39m\n\u001b[32m   1205\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[32m   1206\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1207\u001b[39m                     errfmt.format(\u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name=k),\n\u001b[32m   1208\u001b[39m                     name=k)\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m             ret.append(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[32m   1211\u001b[39m     \u001b[38;5;28mself\u001b[39m.pchanged()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\venvs\\venv1\\Lib\\site-packages\\matplotlib\\artist.py:1055\u001b[39m, in \u001b[36mArtist.set_visible\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m   1052\u001b[39m     \u001b[38;5;28mself\u001b[39m.pchanged()\n\u001b[32m   1053\u001b[39m     \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_visible\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[32m   1056\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1057\u001b[39m \u001b[33;03m    Set the artist's visibility.\u001b[39;00m\n\u001b[32m   1058\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1061\u001b[39m \u001b[33;03m    b : bool\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m b != \u001b[38;5;28mself\u001b[39m._visible:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Train the Agent\n",
    "# -------------------------------------------\n",
    "\n",
    "\"\"\" Input Variables \"\"\"\n",
    "GRID_SIZE = 15\n",
    "NUM_REWARDS = 5\n",
    "NUM_ENEMIES = 0\n",
    "ENEMY_RANDOM_MOVE_RATIO = 0.6\n",
    "NUMBER_OF_EPISODES = 10000\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.95  # 0: only immediate reward matters ; 1.0: future rewards are just as important as immediate ones.\n",
    "EPSILON = 1.0   # initial value for weighting random over policy in taking actions\n",
    "EPSILON_MIN = 0.2\n",
    "EPSILON_DECAY = 0.9999  # multiplies random action chance with this factor after every training\n",
    "BATCH_SIZE = 8  # number of samples to take from the replay buffer for training\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# Define the annealing parameters for beta (Prioritized Replay Buffer)\n",
    "BETA_START = 0.4  # Starting value for beta (usually smaller)\n",
    "BEAT_FRAMES = 10  # Number of frames after which beta will reach 1.0\n",
    "TOTAL_FRAMES = NUMBER_OF_EPISODES * 100  # Total frames in the training\n",
    "\n",
    "RESUME_TRAINING = False\n",
    "MODEL_PATH = r\"E:\\Git_repos\\RL_playground\\CollectAndAvoid\\trained_models\\cnn_models\\dqn_cnn_model_1.pth\"\n",
    "BUFFER_PATH = r\"E:\\Git_repos\\RL_playground\\CollectAndAvoid\\trained_models\\cnn_models\\buffer_CNN_1.pth\"\n",
    "\"\"\" END of Input Variables \"\"\"\n",
    "\n",
    "env = CollectAvoidEnv(grid_size=GRID_SIZE, num_rewards=NUM_REWARDS, num_enemies=NUM_ENEMIES, enemy_random_move_ratio=ENEMY_RANDOM_MOVE_RATIO)\n",
    "agent = DQNAgent(env.action_space.n, np.prod(env.observation_space.shape), lr=LEARNING_RATE, gamma=GAMMA, epsilon=EPSILON,\n",
    "                 epsilon_min=EPSILON_MIN, epsilon_decay=EPSILON_DECAY, batch_size=BATCH_SIZE, buffer_size=BUFFER_SIZE)\n",
    "\n",
    "start_episode = 0\n",
    "start_step = 0\n",
    "\n",
    "# Try loading an existing model\n",
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "         start_episode, start_step = agent.load(MODEL_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved model found, starting from scratch.\")\n",
    "\n",
    "# Try loading an existing buffer\n",
    "if RESUME_TRAINING:\n",
    "    try:\n",
    "        agent.buffer.load(BUFFER_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved buffer found, starting with empty buffer.\")\n",
    "\n",
    "\n",
    "for episode in range(start_episode, NUMBER_OF_EPISODES):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "\n",
    "    # Calculate beta for the current training step (frame_idx)\n",
    "    frame_idx = episode * 50 + step  # Adjust this according to your setup\n",
    "    beta = min(1.0, BETA_START + (BEAT_FRAMES - BETA_START) * frame_idx / TOTAL_FRAMES)\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(state)  # Get action from your agent\n",
    "        next_state, reward, done, _ = env.step(action, episode, step)\n",
    "        step += 1\n",
    "        agent.buffer.add((state, action, reward, next_state, float(done)))\n",
    "\n",
    "        print(f\"E{episode} S{step} | reward: {reward:.3f} | epsilon: {agent.epsilon:.3f} | beta: {beta:.3f}\")\n",
    "\n",
    "        agent.train(beta=beta)\n",
    "        # if episode > 2000:\n",
    "        #     time.sleep(0.1)\n",
    "        \n",
    "    # Every 10 episodes, update target network and save model and buffer\n",
    "    if episode % 10 == 0:\n",
    "        agent.update_target_network()\n",
    "        agent.save(MODEL_PATH, episode, step)\n",
    "        agent.buffer.save(BUFFER_PATH)\n",
    "        print(\"Model and Buffer saved.\")\n",
    "        \n",
    "    print(f\"Episode {episode + 1} finished\")\n",
    "\n",
    "# Save the final model and buffer after training is complete\n",
    "agent.save(MODEL_PATH, episode, step)\n",
    "agent.buffer.save(BUFFER_PATH)\n",
    "print(\"Training complete, model and buffer saved.\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b0d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
